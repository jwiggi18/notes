{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with different file formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Process\n",
    "1. Extract - Data extraction is getting data from multiple sources. Ex. Data extraction from a website using Web scraping or gathering information from the data that are stored in different formats(JSON, CSV, XLSX etc.).\n",
    "\n",
    "2. Transform - Transforming the data means removing the data that we don't need for further analysis and converting the data in the format that all the data from the multiple sources is in the same format.\n",
    "\n",
    "3. Load - Loading the data inside a data warehouse. Data warehouse essentially contains large volumes of data that are accessed to gather insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data from CSV in Python\n",
    "`pandas.read_csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as usual we are using things not explained... is piplite a pythonlite thing?\n",
    "#going to use pip and see how it goes\n",
    "%pip install seaborn lxml openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This whole section is unrunnable outside of Jupyterlite... don't understand how that teaches me anything useful in the real world??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyodide'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyodide\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyfetch\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyodide'"
     ]
    }
   ],
   "source": [
    "#this entire sectio is unusable outside of jupyterlite... apparently\n",
    "#putting it here for reference\n",
    "from pyodide.http import pyfetch\n",
    "\n",
    "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/addresses.csv\"\n",
    "\n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())\n",
    "\n",
    "await download(filename, \"addresses.csv\")\n",
    "\n",
    "df = pd.read_csv(\"addresses.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add a column to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['First Name','Last Name','Location','City','State','Area Code','Income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['First Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['First Name', 'Last Name', 'Location ', 'City','State','Area Code']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting rows using `.loc`\n",
    "\n",
    "`loc()` is label based data selecting method - have to pass the name of the row or column which we want to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first row\n",
    "df.iloc[0]\n",
    "\n",
    "# select the 0th, 1st, and 2nd rows of 'First Name' col\n",
    "df.loc[[0,1,2], 'First Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting rows using `.iloc`\n",
    "`iloc()` is a indexed based selecting method - have to pass integer index in the method to select specific row/column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select the 0th,1st and 2nd row of \"First Name\" column only\n",
    "df.iloc[[0,1,2], 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform fxn in pandas\n",
    "returns a self-produced dataframe with transformed values after applying the fxn specified in its parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c\n",
       "0  1  2  3\n",
       "1  4  5  6\n",
       "2  7  8  9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a data frame from a np array\n",
    "df = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), columns=['a', 'b', 'c']) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.transfrom()` is a pandas method that applies a function to every element in the data frame\n",
    "`func` is the function that is applied to each element\n",
    "in pandas `lambda` x is used apply a function to each element\n",
    "\n",
    "I'm so confused about lambda..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c\n",
       "0  11  12  13\n",
       "1  14  15  16\n",
       "2  17  18  19"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add 10 to each element in the data frame\n",
    "df = df.transform(func = lambda x : x + 10)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sqrt</th>\n",
       "      <th>sqrt</th>\n",
       "      <th>sqrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.316625</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>3.605551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.741657</td>\n",
       "      <td>3.872983</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.123106</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>4.358899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c\n",
       "       sqrt      sqrt      sqrt\n",
       "0  3.316625  3.464102  3.605551\n",
       "1  3.741657  3.872983  4.000000\n",
       "2  4.123106  4.242641  4.358899"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the square root of each element \n",
    "sqrt_df = df.transform(func = ['sqrt'])\n",
    "sqrt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON file format\n",
    "(JavaScript Object Notation) = lightweight data-interchange format\n",
    "\n",
    "Built on two structures:\n",
    "1. A collection of name/value pairs. In various languages, this is realized as an object, record, struct, dictionary, hash table, keyed list, or associative array.\n",
    "\n",
    "2. An ordered list of values. In most languages, this is realized as an array, vector, list, or sequence.\n",
    "\n",
    "JSON is a language-independent data format. It was derived from JavaScript, but many modern programming languages include code to generate and parse JSON-format data. It is a very common data format with a diverse range of applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing JSON to a File\n",
    "usually called serialization - the process of converting an object into a format suitable for transmitting over the network or storing in a file or database.\n",
    "\n",
    "`dump()` or `dumps()` fxn converts Python objects into their respective JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#create a dictionary\n",
    "person = {\n",
    "    'first_name' : 'Mark',\n",
    "    'last_name' : 'abc',\n",
    "    'age' : 27,\n",
    "    'address': {\n",
    "        \"streetAddress\": \"21 2nd Street\",\n",
    "        \"city\": \"New York\",\n",
    "        \"state\": \"NY\",\n",
    "        \"postalCode\": \"10021-3100\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "serialization using dump() function¶\n",
    "`json.dump()` method can be used for writing to JSON file.\n",
    "\n",
    "Syntax: json.dump(dict, file_pointer)\n",
    "\n",
    "Parameters:\n",
    "\n",
    "dictionary – name of the dictionary which should be converted to JSON object.\n",
    "file pointer – pointer of the file opened in write or append mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('person.json', 'w') as f: # writing JSON object\n",
    "    json.dump(person, f) #converting the person library to a json object & saving to 'f' both created above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "serialization using `dumps` fxn\n",
    "`json.dumps()` helps in converting a dictionary to a JSON object.\n",
    "\n",
    "It takes two parameters:\n",
    "\n",
    "dictionary – name of the dictionary which should be converted to JSON object.\n",
    "indent – defines the number of units for indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializing json  \n",
    "json_object = json.dumps(person, indent = 4) \n",
    "  \n",
    "# Writing to sample.json \n",
    "with open(\"sample.json\", \"w\") as outfile: \n",
    "    outfile.write(json_object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"first_name\": \"Mark\",\n",
      "    \"last_name\": \"abc\",\n",
      "    \"age\": 27,\n",
      "    \"address\": {\n",
      "        \"streetAddress\": \"21 2nd Street\",\n",
      "        \"city\": \"New York\",\n",
      "        \"state\": \"NY\",\n",
      "        \"postalCode\": \"10021-3100\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python objects are now serialized to the file. For deserialize it back to the Python object, we use the load() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading JSON to a file\n",
    "This process is usually called Deserialization - it is the reverse of serialization. It converts the special format returned by the serialization back into a usable object.\n",
    "\n",
    "Using `json.load()`\n",
    "The JSON package has `json.load()` function that loads the json content from a json file into a dictionary.\n",
    "\n",
    "It takes one parameter:\n",
    "\n",
    "File pointer : A file pointer that points to a JSON file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_name': 'Mark', 'last_name': 'abc', 'age': 27, 'address': {'streetAddress': '21 2nd Street', 'city': 'New York', 'state': 'NY', 'postalCode': '10021-3100'}}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Opening JSON file \n",
    "with open('sample.json', 'r') as openfile: \n",
    "  \n",
    "    # Reading from json file \n",
    "    json_object = json.load(openfile) \n",
    "  \n",
    "print(json_object) \n",
    "print(type(json_object)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XLSX file format\n",
    "a Microsoft Excel Open XML file format. It is another type of Spreadsheet file format.\n",
    "\n",
    "In XLSX data is organized under the cells and columns in a sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from XLSX file and define the sheet name\n",
    "# will use pandas\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/file_example_XLSX_10.xlsx\", \"sample.xlsx\")\n",
    "\n",
    "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/file_example_XLSX_10.xlsx\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaination from Reddit that kind of made sense:\n",
    "async def means the function is actually a coroutine. All this means essentially is that the function can be “paused” and resume the rest of its execution at a later time. You tell the coroutine where it can be paused by using the await keyword, where the await keyword is followed by an awaitable object. With await you’re essentially saying pause until the awaitable object is done. So it quite literally means await the completion of the object.\n",
    "\n",
    "This “pausing” functionality is not actually useful unless you run your async code within the context of an event loop (one implementation of which is provided through the asyncio library). The event loop will say run this coroutine and when it hits the “pause” point the code execution bubbles back up to the event loop at which point the event loop will look for other coroutines that have satisfied their awaiting condition. When it finds a coroutine whose awaitable object has completed it will give control to that coroutine to execute the code that comes after its await statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyfetch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28;01mawait\u001b[39;00m response\u001b[38;5;241m.\u001b[39mbytes())\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m download(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_example_XLSX_10.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_example_XLSX_10.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(url, filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload\u001b[39m(url, filename):\n\u001b[0;32m----> 2\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mpyfetch\u001b[49m(url)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pyfetch' is not defined"
     ]
    }
   ],
   "source": [
    "#wont run bc pyfetch can only be used in jupyterlite\n",
    "\n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())\n",
    "\n",
    "await download(filename, \"file_example_XLSX_10.xlsx\")\n",
    "\n",
    "df = pd.read_excel(\"file_example_XLSX_10.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
