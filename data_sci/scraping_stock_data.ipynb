{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Stock Data via Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html5lib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from html5lib) (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: lxml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (5.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#new packages\n",
    "%pip install html5lib\n",
    "%pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for some reason I am instructed to ignore warnings, seems shardy but ok\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Netflix stock data from \"yahoo finance\"\n",
    "The website is apparently cached for the course though?\n",
    " https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything from here down is not from the instructions because they do not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for extracting the data\n",
    "1. Send a GET request to the URL of the webpage containing the table.\n",
    "2. Parse the HTML content of the webpage using BeautifulSoup.\n",
    "3. Locate the table element using BeautifulSoup's find or find_all method.\n",
    "4. Extract the table data and convert it into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use `requests` to send a request to the webpapge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send a GET request to the webpage\n",
    "response = requests.get(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Parse the data using `BeautifulSoup`\n",
    "break it down into its individual components, analyze those components to extract desired info or to understand their relationshiops or meanings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `BeautifulSoup` object by passing two arguments to its constructor:\n",
    "1. The HTML or XML\n",
    "2. The name of the parser you want to use (can leave blank and a default will be used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a BeautifulSoup object using the response variable with the method(?) .text & the parser html5lib\n",
    "soup = BeautifulSoup(response.text, 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the table element based on HTML structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract table data into a list of lists\n",
    "data = []\n",
    "for row in table.find_all('tr'): #loop through each table row\n",
    "    row_data = []\n",
    "    for cell in row.find_all(['th','td']): # Loop through each table cell (header or data)\n",
    "        row_data.append(cell.get_text(strip=True)) # Extract the text content of the cell and append to row_data\n",
    "    data.append(row_data) # Append the row_data list to the data list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of lists into a pandas DataFrame\n",
    "df = pd.DataFrame(data[1:], columns=data[0]) # Create a DataFrame using the data list, skipping the first row as header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Date    Open    High     Low  \\\n",
      "0                                        Jun 01, 2021  504.01  536.13  482.14   \n",
      "1                                        May 01, 2021  512.65  518.95  478.54   \n",
      "2                                        Apr 01, 2021  529.93  563.56  499.00   \n",
      "3                                        Mar 01, 2021  545.57  556.99  492.85   \n",
      "4                                        Feb 01, 2021  536.79  566.65  518.28   \n",
      "..                                                ...     ...     ...     ...   \n",
      "66                                       Dec 01, 2015  124.47  133.27  113.85   \n",
      "67                                       Nov 01, 2015  109.20  126.60  101.86   \n",
      "68                                       Oct 01, 2015  102.91  115.83   96.26   \n",
      "69                                       Sep 01, 2015  109.35  111.24   93.55   \n",
      "70  *Close price adjusted for splits.**Adjusted cl...    None    None    None   \n",
      "\n",
      "    Close* Adj Close**       Volume  \n",
      "0   528.21      528.21   78,560,600  \n",
      "1   502.81      502.81   66,927,600  \n",
      "2   513.47      513.47  111,573,300  \n",
      "3   521.66      521.66   90,183,900  \n",
      "4   538.85      538.85   61,902,300  \n",
      "..     ...         ...          ...  \n",
      "66  114.38      114.38  319,939,200  \n",
      "67  123.33      123.33  320,321,800  \n",
      "68  108.38      108.38  446,204,400  \n",
      "69  103.26      103.26  497,401,200  \n",
      "70    None        None         None  \n",
      "\n",
      "[71 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
